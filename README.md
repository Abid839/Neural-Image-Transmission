# Neural-Image-Transmission
# ğŸ¨ Neural Style Transfer Streamlit App

A self-contained web application that lets anyone fuse the **content** of one image with the **style** of another in real time.  
Two engine options are provided:

1. **Classic Neural Style Transfer** (Gatys et al., 2015) â€“ optimises pixels with VGG-19 features.  
2. **Fast Arbitrary Style Transfer** â€“ runs a pre-trained TensorFlow Hub network for instant results.

---

## ğŸ—‚ï¸ Table of Contents
1. [Demo GIF](#demo)  
2. [Key Features](#features)  
3. [How It Works](#how-it-works)  
4. [Quick Start](#quick-start)  
5. [Parameter Cheat-Sheet](#parameters)  
6. [Project Structure](#structure)  
7. [Troubleshooting & Tips](#troubleshooting)  
8. [Roadmap](#roadmap)  
9. [Citation & Credits](#citation)  

---

<a id="demo"></a>
## ğŸ“½ï¸ Demo
![live_demo](docs/demo.gif)  
*Upload â†’ tweak sliders â†’ generate â†’ download, all inside your browser.*

---

<a id="features"></a>
## âœ¨ Key Features

| Category | Details |
|----------|---------|
| **Dual Modes** | *Classic* (VGG-19 optimisation) or *Fast* (TF-Hub stylisation network) |
| **Granular Control** | Tune content/style/TV weights, image resolution, epochs, steps per epoch |
| **Live Previews** | Optional epoch-by-epoch thumbnails during optimisation |
| **Loss Analytics** | Style, content & total losses plotted per training step |
| **One-Click Exports** | Download final stylised PNG **and** loss plot |
| **100 % Streamlit UI** | No HTML/CSS tinkering requiredâ€”share as a simple Python script |
| **GPU Friendly** | Detects and uses CUDA if available; falls back to CPU |

---

<a id="how-it-works"></a>
## ğŸ§‘â€ğŸ”¬ How It Works

### 1. Classic Pipeline
```text
User Images â†¦ Resize/Normalise â†¦ VGG-19 Feature Extractor
                â†³ Content Layers (â„“_c)        â†³ Style Layers (â„“_s)
                â†³ Content Targets (F_c)       â†³ Gram Targets (G_s)

Trainable Image ğ•€ â† optim.Adam â† âˆ‚ğ¿/âˆ‚ğ•€
ğ¿ = Î±â€†Â·â€†Î£_câ€–F_c(ğ•€)âˆ’F_câ€–Â² + Î²â€†Â·â€†Î£_sâ€–G_s(ğ•€)âˆ’G_sâ€–Â² + Î³â€†Â·â€†TV(ğ•€)

	â€¢	Content Loss matches high-level activations of block5_conv2.
	â€¢	Style Loss matches Gram matrices of five early VGG layers.
	â€¢	Total Variation enforces local smoothness.

2. Fast Pipeline

A pre-trained arbitrary style transfer model from TF-Hub is applied in a single forward passâ€”great for demos or batch processing.

â¸»



âš¡ Quick Start

# 1. Clone
git clone https://github.com/<your-user>/neural-style-transfer-app.git
cd neural-style-transfer-app

# 2. (Optional) create a venv
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install deps
pip install -r requirements.txt

# 4. Launch
streamlit run app.py

Open http://localhost:8501 and have fun!

â¸»



ğŸ›ï¸ Parameter Cheat-Sheet

Setting	UI Widget	Typical Range	Effect
Max Image Size	Slider	256 â€“ 1024 px	Higher = sharper but slower & more VRAM
Content Weight (Î±)	Num input	1 â€“ 1 e5	â†‘ = preserve shapes, â†“ = embrace style
Style Weight (Î²)	Num input	1 e-4 â€“ 1 e-1	â†‘ = stronger style textures
TV Weight (Î³)	Num input	0 â€“ 100	â†‘ = smoother output
Epochs	Num input	1 â€“ 20	Re-runs the whole mini-loop
Steps / Epoch	Num input	10 â€“ 500	Gradient steps per epoch


â¸»



ğŸ—ï¸ Project Structure

.
â”œâ”€â”€ app.py                # Streamlit front-end + backend engines
â”œâ”€â”€ requirements.txt      # Pinned Python packages
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ demo.gif          # Screen recording
â”‚   â””â”€â”€ nst_flowchart.png # Architecture diagram
â””â”€â”€ README.md


â¸»



ğŸ©º Troubleshooting & Tips

Issue	Fix
Black image / NaNs	Lower style_weight, reduce learning rate, or start from noise=content mix
CUDA out of memory	Decrease max_dim or steps_per_epoch; close other GPU apps
Streamlit reload loop	See â€œUploading new images resets stateâ€â€”session handling is already built in, but watch for extra st.write calls outside the guarded blocks
Slow CPU run	Enable a local/Colab GPU, or switch to Fast TF-Hub mode


â¸»



ğŸ›£ï¸ Roadmap
	â€¢	ğŸ¥ Batch video style transfer
	â€¢	ğŸ’¾ Checkpoint resume & intermediate saving
	â€¢	ğŸ–¼ï¸ Style mixing (alpha blend two style images)
	â€¢	ğŸŒ One-click deployment to Streamlit Cloud / HuggingFace Spaces
	â€¢	ğŸ“ Unit tests & CI workflow

â¸»



ğŸ“ Citation & Credits

@article{gatys2015nst,
  title   = {A Neural Algorithm of Artistic Style},
  author  = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
  journal = {arXiv preprint arXiv:1508.06576},
  year    = 2015
}

	â€¢	Fast style model courtesy of Google Magenta
	â€¢	Built with TensorFlow 2, TensorFlow Hub, Streamlit, and Matplotlib
	â€¢	Flowchart created using Mermaid.js

â¸»

Made with â¤ï¸ & NumPy by <Your Name>
PRs and â­ stars are always welcome!

---

### What changed vs. the earlier version?

1. **Deeper explanation** under *How It Works* with equations and layer names.  
2. **Parameter cheat-sheet** plus effects to guide users.  
3. Added **Troubleshooting**, **Roadmap**, and **Table of Contents**.  
4. Kept a crisp, student-tech tone while being GitHub-ready.

Feel free to swap in your real demo GIF, adjust the repo URL, and credit yourself. Let me know if youâ€™d like a matching `LICENSE`, `CONTRIBUTING.md`, or Dockerfile.
